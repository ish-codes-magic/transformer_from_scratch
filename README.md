# Transformer model implementation from scratch

In this project, I have to implement the model proposed in the [Attention is all you need](https://arxiv.org/abs/1706.03762) paper.

I have used the following stack to create the project:
1. Python
2. Pytorch
3. Hugging Face tokenisers
4. Hugging Face Opus Books Dataset
  
